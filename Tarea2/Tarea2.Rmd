---
header-includes:
- \usepackage{longtable}
- \usepackage[utf8]{inputenc}
- \usepackage[spanish]{babel}\decimalpoint
- \setlength{\parindent}{1.25cm}
- \usepackage{amsmath}
- \usepackage{xcolor}
- \usepackage{cancel}
- \usepackage{array}
- \usepackage{float}
- \usepackage{multirow}
output:
  pdf_document:
    number_sections: yes
  html_document:
    df_print: paged
fontsize: 12pt
papersize: letter
geometry: margin = 1in
language: es
editor_options:
  markdown:
    wrap: 72
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, warning =FALSE, message = FALSE, fig.align = "center", fig.height = 3.5, fig.pos = "H")

#librerias
library(tidyverse)
library(magrittr)
library(kableExtra)
library(xtable)
library(corrplot)
library(hrbrthemes)
library(ggplot2)
library(GGally)



#Selection of variables procedures 
library(olsrr)

#naive bayes
library(naivebayes)
library(e1071)
#knn
library(MASS)
library(class)
library(dummies)

#curva roc y modelo lda
library(ISLR)
library(MASS)
library(Amelia)
library(pscl)
library(caret)
library(pROC)
library(ROCR)
library(wesanderson)
```


```{=tex}
\input{DocumentFormat/titlepage.tex}
\thispagestyle{empty}
\tableofcontents
\newpage
\thispagestyle{empty}
\listoffigures
\newpage
```

```{=tex}
\pagestyle{myheadings}
\setcounter{page}{4}
```

\section{Ejercicio1}
<!-- Daniel Hoyos -->



```{r db-ej1}
bank<-read.csv("Data/bank.csv", stringsAsFactors=TRUE, header = TRUE, sep = ",")
attach(bank)
```


\subsection{Análisis descriptivo de la base de datos bank}

La base de datos bank, contiene un total de 17 variables y 11.162 observaciones, de las cuales 7 son de tipo numéricas y 10 son de tipo categórica, esta base de datos resume algunas características acerca de clientes de un banco en particular tales como la edad(age), el tipo de trabajo que desempeña(job), el estado marital(marital), nivel educativo(education),si ha cometido o no alguna falta pagos(default), el estado de sus fondos económicos(balance), si el cliente tiene o no algún préstamo de vivienda(housing), si el cliente tiene o no algún préstamo (loan), medio de contacto con el cliente(contact),fecha de afiliación(day, month),tiempo de vencimiento (El tiempo de vencimiento). entre otras, a continuación veremos un pequeño resumen de las variables. 

```{r, fig.align='center', fig.width=70, fig.height=80}
kable(summary(bank[1:5]))
kable(summary(bank[6:11]))
kable(summary(bank[12:17]))
```

```{r, warning=FALSE, message=FALSE}
base<-bank[,c(1,6,10,12,13)]


gg2<-ggpairs(base,
             upper=list(continuous = wrap("smooth",alpha = 0.3, size=1.2,
                                               method = "lm")),
             lower=list(continuous ="cor"))

for(i in 1:ncol(base)){
  gg2[i,i]<-gg2[i,i]+
    geom_histogram(breaks=hist(base[,i],breaks = "FD",plot=F)$breaks,
                   
                   colour = "red",fill="lightgoldenrod1")
  
}

gg2
```




El gráfico anterior es importante para identificar el posible comportamiento de nuestras variables numéricas, en este caso vemos que existe poca relación lineal entre las mismas, situación que nos da una idea de pensar que es poco probable que existan problemas de multicolinealidad.


```{r , include=T,echo=F}
par(mfrow=c(2,3))
plot(factor(loan),age,xlab='loan',ylab='age',main='loan vs age')
plot(factor(loan),day,xlab='loan',ylab='day',main='loan vs day')
plot(factor(loan),duration,xlab='loan',ylab='duration',main='loan vs duration')
plot(factor(loan),balance,xlab='loan',ylab='balance',main='loan vs balance')
plot(factor(loan),xlab='loan',main='loan ')
```


La variable loan, es una de las variables de mayor interés en el estudio, es una variable dicótoma que representa si un cliente tiene o no algún préstamo, del gráfico anterior, claramente no hay diferencia en mediana para la variable loan con respecto a  la edad, día ,duración y balance, por otra parte, vemos que la mayoría de personas no tienen ningún tipo de préstamo.


## a) cree un conjunto de datos de entrenamiento del 75% y el restante 25% tratetelo como datos de test o prueba.


```{r, echo=TRUE}
df=data.frame(bank)
smp_sz <- floor(0.75 * nrow(df))
train_ind <- sample(seq_len(nrow(df)), size = smp_sz)

train <- df[train_ind, ] #datos de Entrenamiento 75%
test <- df[-train_ind, ] #datos de Test 25%

y_train=df[train_ind,8]
y_test=df[-train_ind,8]
```

\subsection{b)Con los datos de entrenamiento implemente naive bayes usando loan como el supervisor y las demas como pedictores.}

El clasificador Naive de Bayes asume que todas las features (componentes del vector x) son independientes y que son igualmente importantes. Con este supuesto, la probabilidad (Likelihood-verosilimitud) de observar el vector de features x = (x1, x2, . . . , xp) con p =1...16 dado que se esta en la clase j es:


$$Pr(x|Y=j)=Pr(x_1|Y=j)*...*Pr(x_p|Y=j)$$


Por el teorema de bayes tenemos:


$$Pr(y=j|x)=\frac{Pr(x|Y=j)(Pr(Y=j))}{Pr(x)}$$


lo anterior representa un modelo bayesiando donde, la distribucion posterior, esta representada por el producto de la verosimilitud y la probabilidad a priori.


ahora, vamos a implementar un modelo de naivebayes para calcular la probabilidad de que los proximos clientes tengan o no un credito.

 

```{r, echo=TRUE}
#modelo naive bayes
naiveB.fit <- naiveBayes(loan~., data=train,laplace=0.128)

#predict train and testing
predict_test<-predict(naiveB.fit,test,type="class")
predict_train<-predict(naiveB.fit,train,type="class")

#prediccion probabilidades
predict_train2<-predict(naiveB.fit,train,type="raw")
predict_test2<-predict(naiveB.fit,test,type="raw")
```

\subsection{c) Con los datos de entrenamiento, Implemente un modelo Knn con loan como supervisor y las demás como predictoras. utilizar varios valores de k, pero reportar solo uno.}

El modelo knn también conocido como k vecinos más cercanos, es una metodología muy eficiente que permite a partir de un valor de k, tomar los k valores más cercanos de una estimación para ajustarse a su comportamiento, a medida que incrementamos el valor de k, se tiende a perder la señal y comenzamos a guiarnos por el ruido del modelo, por lo tanto, se debe tener cuidado a la hora de utilizar esta metodología. 
por otra parte, en este modelo, se deben crear vectores de variables dummy para las variables categóricas, y las variables continuas se deben normalizar. cómo se verá a continuación.



```{r, echo = TRUE}
#modelo KNN
normalize <- function(x) {
norm <- ((x - min(x))/(max(x) - min(x)))
return (norm)
}
#variables categoricas, a vectores de dummy.
suppressWarnings(dummyjob<-dummy(df$job, sep="_"))
suppressWarnings(dummyMarital<-dummy(df$marital, sep="_"))
suppressWarnings(dummyEducation<-dummy(df$education, sep="_"))
suppressWarnings(dummydefault<-dummy(df$default ,sep="_"))
suppressWarnings(dummyhousing<-dummy(df$housing, sep="_"))
suppressWarnings(dummycontact<-dummy(df$contact ,sep="_"))
suppressWarnings(dummymonth<-dummy(df$month, sep="_"))
suppressWarnings(dummypoutcome<-dummy(df$poutcome, sep="_"))
suppressWarnings(dummydeposit<-dummy(df$deposit, sep="_"))

#normalización de las variables numericas.
age<-normalize(df$age)
balance<-normalize(df$balance)
day<-normalize(df$day)
duration<-normalize(df$duration)
campaign<-normalize(df$campaign)
pdays<-normalize(df$pdays)
previous<-normalize(df$previous)

#nueva base de datos, con las variables transformadas.
Newdata<-cbind(df,dummyjob,dummyMarital,dummyEducation,
               dummydefault,dummyhousing,dummycontact,dummymonth,
              dummypoutcome,dummydeposit,age,balance,day,duration,
              campaign,pdays,previous)

#nueva selección de datos de entrenamiento y test
train1 <- Newdata[ train_ind,18:50 ]
test1 <- Newdata[-train_ind,18:50 ]
y_train1=df[train_ind,8]
y_test1=df[-train_ind,8]

#Modelo 1 k=1
#fit.knn_train<-knn(train=train1, test=train1,cl=y_train1, k=1, prob=TRUE)
#fit.knn_Test<-knn(train=train1, test=test1,cl=y_train1, k=1, prob=TRUE)

#Modelo 2 k=2 modelo seleccionado
fit.knn_train<-knn(train=train1, test=train1,cl=y_train1, 
                   k=2, prob=TRUE,use.all=TRUE)

fit.knn_Test<-knn(train=train1, test=test1,cl=y_train1, k=2, prob=TRUE)

#modelo 3 k= 5
#fit.knn_train<-knn(train=train1, test=train1,cl=y_train1, 
#k=5, prob=TRUE,use.all=TRUE)
#fit.knn_Test<-knn(train=train1, test=test1,cl=y_train1, k=5, prob=TRUE)

#predict para verificar el ajuste de nuestros datos de Test.
Predicted_train<-factor(fit.knn_train)
Predicted_test<-factor(fit.knn_Test)

#probabilidades
prob_train <- attr(fit.knn_train, "prob")
prob_test <- attr(fit.knn_Test, "prob")
```

\subsection{d)Con los datos de entrenamiento, implemente un modelo Logístico con loan como supervisor y las demás como predictoras.}

### Planteamiento del Modelo.

$$Logit(\pi_i)=\log(\frac{\pi_i}{1-\pi_i})= \beta_0 + \beta_{1xi1}+ \beta_{2xi2}+...+\beta_{kxik}$$

El modelo logístico, es una variación del modelo de regresión lineal en el que la variable respuesta es una variable dicótoma, es decir solo toma 2 valores 0 ó 1, es por esto que el logit, o el logaritmo de la razón de dos se utiliza como su predictor lineal.
este modelo es naturalmente un modelo de clasificación, por lo anterior, el resultado que se va obtener es la probabilidad asociada a si una persona con diversas características tiene o no un crédito. para mayor comprensión, el modelo ajustado entregara el resultado de evaluar la siguiente expresión:


$$\pi_i= \frac{e^{\beta_0+\beta_{1xi1}+\beta_{2xi2}+...+\beta_{kxik}}}{1+e^{\beta_0+\beta_{1xi1}+\beta_{2xi2}+...+\beta_{kxik}}}$$

Si el valor de la probabilidad es mayor a 0.5 entonces esta persona tiene un crédito(loan=si), en caso contrario, no tiene crédito(loan=no).

```{r, echo = TRUE}
#Modelo logístico.
lr.fit=glm(as.factor(loan)~., data = train, family=binomial)

#predict para verificar ajuste.
lrPred_train<-predict(lr.fit,train, type = c("response"))
lrPred_test<-predict(lr.fit,test, type = c("response"))

#clasificación 
predict_lr_train<-ifelse(lrPred_train<=0.5,0,1)
predict_lr_test<-ifelse(lrPred_test<=0.5,0,1)
```

\subsection{e) Con los datos de entrenamiento, implemente un modelo LDA con loan como supervisor y las demás como predictoras. 
En LDA se modela la distribución de los predictores X de manera
separada en cada una de las categorías de respuesta (es decir, condicionando en Y ) y luego se usa el teorema de Bayes para obtener estimaciones de $Pr (Y = k | X = x)$ Cuando estas distribuciones se asumen normales, el modelo es muy similar en forma al de regresión logística. esta probabilidad de clasificaci;on esta dada por:}

$$Pr (Y = k | X = x)=\frac{\pi_kf_k(x)}{\sum_{l=1}^{k}\pi_lf_l(x)}$$

```{r, echo = TRUE}
#modelo LDA
lda.fit <- lda(as.factor(loan) ~., data=train)

#prediccion
predict_train_lda<-predict(lda.fit,train,type=c("class"))
predict_test_lda<-predict(lda.fit,test,type=c("class"))

#clasificación
train_lda<-ifelse(as.factor(train$loan)==predict_train_lda$class,0,1)
test_lda<-ifelse(as.factor(test$loan)==predict_test_lda$class,0,1)
```

\subsection{f) Con los datos de entrenamiento calcular training MSE, matriz confusión y curva roc para cada uno de los modelos.}


```{r, }
#training

#Matriz de confusión y  NB error
t_NB<-table(predict_train,y_train)
Train_error_NB<-(t_NB[1,2]+t_NB[2,1])/(sum(t_NB))
sensitidad_NB<-t_NB[2,2]/(t_NB[2,2]+t_NB[1,2])
especificidad_NB<-t_NB[1,1]/(t_NB[1,1]+t_NB[2,1])

#Matriz de confusión y knn error
t_KNN<-table(Predicted_train,y_train)
Train_error_Knn<-(sum(t_KNN[1,2],t_KNN[2,1]))/(sum(t_KNN))
sensitidad_knn<-t_KNN[2,2]/(t_KNN[2,2]+t_KNN[1,2])
especificidad_knn<-t_KNN[1,1]/(t_KNN[1,1]+t_KNN[2,1])

#Matriz de confusión y logistic error
T_lr<-table(as.factor(train$loan),predict_lr_train)
lr_train_err<-(T_lr[1,2]+T_lr[2,1])/(sum(T_lr))
sensitidad_lr<-T_lr[2,2]/(T_lr[2,2]+T_lr[1,2])
especificidad_lr<-T_lr[1,1]/(T_lr[1,1]+T_lr[2,1])

#Matriz de confusión y lda error
t_Lda<-table(as.factor(train$loan),train_lda)
LDA_train_err<-(t_Lda[1,2]+t_Lda[2,1])/(sum(t_Lda))
sensitidad_lda<-t_Lda[2,2]/(t_Lda[2,2]+t_Lda[1,2])
especificidad_lda<-t_Lda[1,1]/(t_Lda[1,1]+t_Lda[2,1])

list(NaiveBayes=t_NB,Train_NaiveBayes_err=Train_error_NB,
     Knn=t_KNN,Train_error_Knn=Train_error_Knn,
     logistic_reg=T_lr,lr_train_err=lr_train_err,
     Lda=t_Lda,LDA_train_err=LDA_train_err)


list(sensitividad_NaiveBayes=sensitidad_NB,Especificidad_NaiveBayes=especificidad_NB,
     sensitividad_Knn=sensitidad_knn,Especificidad_Knn=especificidad_knn,
    sensitividad_logistic_reg=sensitidad_lr,Especificidad_lr=especificidad_lr,
    sensitividad_Lda=sensitidad_lda,Especificidad_LDA=especificidad_lda)
     
```


```{r, }
#curvas Roc testing

par(mfrow=c(2,2))
#roc NB
plot(roc(as.factor(train$loan),1-predict_train2[,1],direction="<"),
     col="purple2", lwd=3, main="ROC curve NaiveBayes train",print.auc=T,print.thres = "best")

#roc knn
plot(roc(as.factor(train$loan),1-prob_train,direction="<"),
     col="purple2", lwd=3, main="ROC curve Knn k=2 train",print.auc=T,print.thres = "best")

#roc LR
plot(roc(as.factor(train$loan),lrPred_train,direction="<"),
     col="purple2", lwd=3, main="ROC curve Logistic regresion train",print.auc=T,print.thres = "best")

#roc LDA
plot(roc(as.factor(train$loan),1-predict_train_lda$posterior[,1],direction="<"),
     col="purple2", lwd=3, main="ROC curve LDA train",print.auc=T,print.thres = "best")

```


\subsection{g) Con los datos de test calcular training MSE, matriz confusión y curva roc para cada uno de los modelos.}

```{r, }
#testing

#Matriz de confusión y  NB error
t1_NB<-table(predict_test,y_test)
Test_error_NB<-(t1_NB[1,2]+t1_NB[2,1])/(sum(t1_NB))

#Matriz de confusión y knn error
t1_KNN<-table(Predicted_test,y_test1)
Test_error_Knn<-(sum(t1_KNN[1,2],t1_KNN[2,1]))/(sum(t1_KNN))

#Matriz de confusión y logistic error
T1_lr<-table(as.factor(test$loan),predict_lr_test)
lr_test_err<-(T1_lr[1,2]+T1_lr[2,1])/(sum(T1_lr))

#Matriz de confusión y lda error
t1_Lda<-table(as.factor(test$loan),test_lda)
LDA_test_err<-(t1_Lda[1,2]+t1_Lda[2,1])/(sum(t1_Lda))
sensitidad_ldatest<-t1_Lda[2,2]/(t1_Lda[2,2]+t1_Lda[1,2])
especificidad_ldatest<-t1_Lda[1,1]/(t1_Lda[1,1]+t1_Lda[2,1])


list(NaiveBayes=t1_NB,Test_error_NB=Test_error_NB,
     Knn=t1_KNN,Test_error_Knn=Test_error_Knn,
     logistic_reg=T1_lr,lr_test_err=lr_test_err,
     Lda=t1_Lda,LDA_test_err=LDA_test_err)
```

```{r , include=T,echo=FALSE}
#curvas Roc testing

par(mfrow=c(2,2))
#roc NB
plot(roc(as.factor(test$loan),1-predict_test2[,1],direction="<"),
     col="purple2", lwd=3, main="ROC curve NaiveBayes test",print.auc=T,print.thres = "best")

#roc knn
plot(roc(as.factor(test$loan),1-prob_test,direction="<"),
     col="purple2", lwd=3, main="ROC curve Knn k=2 test",print.auc=T,print.thres = "best")

#roc LR
plot(roc(as.factor(test$loan),lrPred_test,direction="<"),
     col="purple2", lwd=3, main="ROC curve Logistic regresion test",print.auc=T,print.thres = "best")

#roc LDA
plot(roc(as.factor(test$loan),1-predict_test_lda$posterior[,1],direction="<"),
     col="purple2", lwd=3, main="ROC curve LDA test",print.auc=T,print.thres = "best")

```

\subsection{h) Con cual modelo observo mejor desempeño y por qué?}
Para seleccionar el mejor modelo, es muy importante tener claro que es lo que se quiere responder. La variable loan como se dijo anteriormente representa si una persona tiene o no un crédito, esto es importante porque cometer un error de darle un crédito a una persona ya tenía uno o no darle un crédito a una persona que no lo tenía, es una decisión que genera un gran impacto negativo en las ganancias del banco, por lo cual, el modelo seleccionado debe cumplir con unos altos índices de sensitividad y de especificidad.
de lo anterior, sin duda alguna el modelo LDA, obtuvo unos índices de sensibilidad y de especificad superiores al 96%, lo cual es una excelente tasa de clasificación, por esta razón se selecciona como el mejor modelo, a pesar de que el AUC de las curvas Roc sean similares para todos los demás modelos.

```{r clean-env}
rm(list = ls())
```



\section{Ejercicio2}
<!-- Santiago Rojas -->

\subsection{Breve analisis Exploratorio} 

La base de datos costumer_loan_details, cuenta con un 12 variables y 114 observaciones de las cuales 4 son variables de tipo numérico y 8 son variables de tipo categóricas. Dicha base de datos tiene características de los cliente como lo son: state, gender, race, marital_status, occupation, credit_score, income, debts, loan_type, loan_decision_type.  

```{r, fig.align='center', fig.width=80}
data <- read.csv("Data/costumer_loan_details.csv",  
                 stringsAsFactors=TRUE, header = TRUE, sep = ",")
kable(summary(data[2:5]))
```
```{r, fig.align='center', fig.width=80}
kable(summary(data[6:10]))
```
```{r,fig.align='center', fig.width=80}
kable(summary(data[11:12]))
```



Del resumen numérico anterior se tiene: 

* El **state** con mayor numero de observaciones es **Other= 68** y el segundo mayor es **OH = 11**.

* El **gender** con mayor numero de observaciones es **Male = 91** y el gender con menor observaciones es **Female = 91**.

* El *age** promedio es de **39 años**.

* El *race** con mayor numero de observaciones es **American Indian or Alaska Native = 26**.

* El **marital_status** con mayor numero de observaciones es **Married = 44** y el siguiente con mayor numero de observaciones es **Single = 43**. 

* La **ocupation** con mayor numero de observaciones es **NYPD = 28** y el siquiente con mayor numero de observaciones es **IT = 27**. 

* El **credit_score** promedio es de **695.8**. 

* El **income** promedio es de **9338**. 

* El **debts** promedio es de **2744**. 

* El **loan_type** con mayor numero de observaciones es **Auto = 40** y el siguiente con mayor numero de observaciones es **Personal = 34**. 

* El **loan_decision_type** con mayor numero de observaciones es **Approved = 70 ** y el siguiente con mayor numero de observaciones es **Denied = 32**. 

```{r, message=FALSE, warning=FALSE}
base<-data[,c(4,8,10, 9)]


gg2<-ggpairs(base,
             upper=list(continuous = wrap("smooth",alpha = 0.3, size=1.2,
                                               method = "lm")),
             lower=list(continuous ="cor"))

for(i in 1:ncol(base)){
  gg2[i,i]<-gg2[i,i]+
    geom_histogram(breaks=hist(base[,i],breaks = "FD",plot=F)$breaks,
                   
                   colour = "red",fill="lightgoldenrod1")
  
}

gg2
```

Este gráfico nos permite mirar y evidenciar relaciones lineales entre las variables. 

Se puede observar relaciones lineales de interés entre las variables como los son: 

* Se observa una alta correlación  entre las variables **income** y **age** 
igual a **0.838**.

* Se observa una alta correlación  entre las variables **income** y **debts** 
igual a **0.818**.

* Se observa una moderada correlación entre las variables **age** y **debts** 
igual a **0.762**.

* Se observa una baja correlación entre las variables **age** y **credit_score** 
igual a **0.142**. 


## a) Cree un conjunto de datos de entrenamiento del 75% y el restante 25% trátelo como datos de test o de prueba. 

Se fija una **semilla = 123** con el fin de permitir replicabilidad del trabajo. Luego procedemos a crear el conjunto
de datos para entrenamiento **train** de un valor del **75%** de los datos para un total de **85 observaciones** y el 
conjunto de datos para prueba **test** de un valor del **25%** de los datos para un total de **29 observaciones**. 
Se define **income** como el supervisor **"Y"** y  la característica **debts** como predictor. 

```{r db-ej2, echo=TRUE, message=FALSE}
library(caret)
data <- read.csv("Data/costumer_loan_details.csv",  
                 stringsAsFactors=TRUE, header = TRUE, sep = ",")

set.seed(123) 



smp_sz <- floor(0.75 * nrow(data))
train_indx <- sample(seq_len(nrow(data)), size = smp_sz)

train <- data[train_indx, 10]
train_scale <- scale(data[train_indx, 10])
test <- data[-train_indx,10]
test_scale  <- scale(data[-train_indx,10])

y_train <- data[train_indx, 9] 
y_test <- data[-train_indx, 9] 

```

\subsection{b)Con los datos de entrenamiento, implemente Knn(con al menos tres valores para k) usando income como el supervisor y debts como predictor. Grafique e interprete.}

Con la ayuda de la libreria **caret** se realiza una regresión knn con un parametro de k = 16. Mas adelante se explica por que se obta por usar ese k. 

```{r knn-ej2, echo=TRUE}
knnmodel = knnreg(train_scale, y_train, k = 16)

pred_y = predict(knnmodel, data.frame(test_scale))

mse = mean((y_test - pred_y)^2)
mae = caret::MAE(y_test, pred_y)
rmse = caret::RMSE(y_test, pred_y)

#cat("MSE: ", mse, "MAE: ", mae, " RMSE: ", rmse)
```

| MSE | MAE | RMSE |
| --- | --- | ---- |
|  4398259 | 1814.891 | 2097.203 | 


```{r}
r1 <- cbind(test, y_test, 1) 
r2 <- cbind(test, pred_y, 2)

new_df <- rbind(r1, r2) %>% as.data.frame()
new_df$V3 <- as.factor(new_df$V3)
colnames(new_df) <- c("test", "y", "Valor")
new_df <- new_df %>% mutate(., Valor = if_else(Valor == "1", "Real", "Predicho"))

ggplot(new_df, aes(test, y, shape=Valor, size = Valor, color = Valor)) + 
  geom_point(size = 4)+
  scale_colour_discrete("Valor")+
  xlab("Debts")+
  ylab("Income")+
  ggtitle("Datos de prueba (Test)")+
  theme_bw()
```



```{r}
ggplot(new_df, aes(test, y, color = Valor)) + 
  geom_line()+
  geom_point()+
  scale_colour_discrete("Valor")+
  xlab("Debts")+
  ylab("Income")+
  ggtitle("Datos de prueba (Test)")+
  theme_bw()
```
De la anteriores gráficas se puede observar que las prediciones dadas por nuestro modelo de regresión knn son relativamente buenas ya que el modelo trata de capturar la tendencia y no el ruido, si es comparado entre las predicciones que puede arrojar otros modelos de knn. 

```{r}
n_iterations =  50

ans = c()

for(i in 1:n_iterations){
  knnmodel = knnreg(train_scale, y_train, k = i)
  pred_y = predict(knnmodel, data.frame(test_scale))

  mse = mean((y_test - pred_y)^2)
  ans[i] <- mse
}

db <- data.frame(k=c(1:n_iterations), db=ans)

db %>%
  ggplot(aes(k,db)) + geom_line() +
  geom_vline(xintercept = 16, linetype = 'dashed') +
  theme_minimal() +
  scale_x_continuous(breaks = seq(0,n_iterations,2)) +
  labs(title = 'MSE para diferentes valores de k')+
  ylab("MSE")

```

Nuestro modelo de regresión knn fue entrenado con 85 observaciones de un total de 114 y se toma **k = 16** por que es el modelo con menor **MSE = 4398259**, **MAE = 1814.891** , **RMSE = 2097.203** y cumple con ser el más parsimonioso entre los modelos de k = 17 hasta k = 50. 

\subsection{c) Con los datos de entrenamiento, implemente regresión lineal simple usando income como el supervisor y debts como predictor. Grafique e interprete.}

#### Correlación entre el supervisor (Income) y el predictor (debts). Datos de entrenamiento

```{r}
train_df <- cbind(train, y_train) %>% as.data.frame()
colnames(train_df) <- c("debts", "income")


corrplot(cor(train_df), method="numb", type="upper")
```

Se observa una relación lineal **media-alta** entre el supervisor **income** y el predictor **debts**. 


#### Modelo lineal

 
 $$Y \approx \beta_0 + \beta_1X_i + \epsilon_i; \: \epsilon_i \sim N(0, \sigma^2)$$



```{r lm-ej2, echo = TRUE}
model <- lm(y_train ~ debts, data=train_df)
```

$$\hat{Y} \approx 4584.5801 + 1.7285X_i + \epsilon_i; \: \epsilon_i \sim N(0, \sigma^2)$$


#### Anova 


```{r, eval = FALSE}
summary(model)
```


```{r}
kable(xtable(summary(model)))
```

#### Pruebas de hipotesis: Significancia del modelo. 

$$H_0: \beta_i = 0 \: vs \: H_i: \beta_i = 0$$
Con una significancia de $\alpha = 0.05$ y observando los p-valores para $\beta_0$ y para $\beta_1$ hay evidencia suficiente para rechazar a $H_0$ esto quiere decir que el modelo es significativo. 


#### Pruebas de hipotesis: Supuesto de normalidad.

$$H_0:\ \varepsilon_i\sim\ \text{ Normal.  vs }\ H_1:\ \varepsilon_i\not\sim\text{ Normal}$$

```{r}
res <- residuals(model)
shapiro <- shapiro.test(res)
shapvalue <- ifelse(shapiro$p.value < 0.001, "P value < 0.001", 
                    paste("P value = ", round(shapiro$p.value, 4), sep = ""))
shapstat <- paste("W = ", round(shapiro$statistic, 4), sep = "")
q <- qqnorm(res, plot.it = FALSE)
qqnorm(res, main = "Normal Q-Q Plot of Residuals")
qqline(res, lty = 2, col = 2)
text(min(q$x, na.rm = TRUE), max(q$y, na.rm = TRUE)*0.95, pos = 4,
     'Shapiro-Wilk Test', col = "blue", font = 2)
text(min(q$x, na.rm = TRUE), max(q$y, na.rm = TRUE)*0.80, pos = 4,
     shapstat, col = "blue", font = 3)
text(min(q$x, na.rm = TRUE), max(q$y, na.rm = TRUE)*0.65, pos = 4,
     shapvalue, col = "blue", font = 3)

```

Como el patrón de los residuales sigue en su mayoría la línea roja que representa el ajuste de la distribución de los residuales a una distribución normal, se concluye que el supuesto de normalidad se cumple. Lo cual se ratifica en el resultado de la prueba de normalidad de Shapiro-Wilk con un valor-P mayor a 0.05, por lo cual no se rechaza $H_0$ y se concluye que los residuales se distribuyen normal.


#### Supuesto de varianza constante.

Se realizó una prueba gráfica comparando los residuales con los valores ajustados para analizar su distribución.

```{r, echo=FALSE, out.width="60%", fig.align='center'}
# Cálculo de residuales estudentizados y valores ajustados
res.stud <- round(residuals(model), 4)
yhat <- model$fitted.values
# Gráfico de Residuales estudentizados vs. Valores ajustados
plot(yhat, res.stud, xlab = "Valores Ajustados", ylab = "Residuales", main = "Residuales vs. Valores ajustados")
abline(h = 0, lty = 2, col = 2)
```
    
De la gráfica se observa que el patrón formado por la nube de puntos no se aleja mucho de un patrón rectangular. Lo que nos da un indicio de homocedasticidad de varianza. 




```{r}
train_df %>% ggplot(., aes(x=debts, y=income))+
  geom_point()+
  geom_smooth(method=lm , color="red", fill="#69b3a2", se=TRUE)+
  theme_classic()
  
```

Del gráfico anterior y de las pruebas realizada nos permite concluir que una regresión lineal puede ser un modelo adecuado para poder explicar **income** dado que un cliente tiene una determinadad caracteristica **debts**. 


\subsection{d) Use los respectivos ajuste de cada uno de los modelos anteriores y con el conjunto de prueba, calcule el test-MSE. Qué observa?}



```{r, echo = TRUE, eval = FALSE}
test_df <- cbind(test, y_test) %>% as.data.frame()
colnames(test_df) <- c("debts", "income")

#testMSE Regresion lineal
preds <- predict(model, test_df)
modelEval <- cbind(test_df$income, preds) %>% as.data.frame()
mse_ml <- mean((modelEval$V1 - modelEval$preds)^2)
mse_ml

#testMSE Regresion KNN
pred_y = predict(knnmodel, data.frame(test_scale))
mse_knn = mean((y_test - pred_y)ˆ2)
mse_knn
```


| testMSE Regresión Lineal | testMSE Regresión Knn |
| ------------------------ | --------------------- |
|     3224949              |     4398259           |


Se observa que el modelo con menor **test MSE** es el de la regresión lineal. Dicho modelo a parte de hacer una mejor predicción también permite hacer inferencia, se recomienda dicho modelo como el modelo mas adecuado comparado respecto a los modelos obtenidos usando el método de aprendizaje estadístico KNN. 

\subsection{e) Usando todos los datos y regresión lineal multiple seleccione un modelo usando forward, backward y stepwise}

#### Forward

```{r, fig.width=70}
ols_step_forward_aic(lm(income ~., data=data[, 2:12,]))
```

#### Backward

```{r, fig.width=80}
ols_step_backward_aic(lm(income ~., data=data[, 2:12,]))
```

#### Stepwise 

```{r, fig.width=70}
ols_step_both_aic(lm(income ~., data=data[, 2:12,]))
```

\subsection{f) Seleccione uno de los modelos del paso anterior y responda con argumentación la pregunta: Ajusta bien dicho modelo?}

Dado que los métodos de selección automáticos como: Forward y Stepwise nos indican que dos modelo plausibles para explicar **income** son el modelo con la covariable **marital_status** y el modelo con la covariable **debts** obtamos por seleccionar el modelo con la covariable **debts** ya que cuenta con una de las mejores metricas(AIC, R-sq, Adj.R-sq) dadas por el metodo de selección automático de variables y como vimos anteriormente es un modelo que cumple con los supuesto de un modelo lineal ademas de tener una mejor predicción que los modelos de regresión Knn visto en este trabajo. Lo que nos permite concluir que dicho modelo es adecuado y tiene un buen ajuste. 


\section{Ejercicio3}
<!-- Genaro Aristizabal -->

\section{Ejercicio4}
<!-- Genaro Aristizabal -->
